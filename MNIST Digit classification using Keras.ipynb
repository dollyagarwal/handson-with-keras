{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (60000, 28, 28)\n",
      "Train label shape:  (60000,)\n",
      "Test data shape:  (10000, 28, 28)\n",
      "Test label shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import mnist\n",
    "\n",
    "train_images=mnist.train_images()\n",
    "train_labels=mnist.train_labels()\n",
    "\n",
    "test_images=mnist.test_images()\n",
    "test_labels=mnist.test_labels()\n",
    "\n",
    "print(\"Train data shape: \",train_images.shape)\n",
    "print(\"Train label shape: \",train_labels.shape)\n",
    "print(\"Test data shape: \",test_images.shape)\n",
    "print(\"Test label shape: \",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (60000, 784)\n",
      "Test data shape:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "##Data Preparation\n",
    "\n",
    "##Normalize the pixel values of images from [0, 255] to [-0.5, 0.5] to make our network easier to \n",
    "##train (using smaller, centered values is often better).\n",
    "\n",
    "train_images=(train_images/255)-0.5\n",
    "test_images=(test_images/255)-0.5\n",
    "\n",
    "#Flatten the images \n",
    "train_images=train_images.reshape((-1,784))\n",
    "test_images=test_images.reshape((-1,784))\n",
    "\n",
    "print(\"Train data shape: \",train_images.shape)\n",
    "print(\"Test data shape: \",test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Building Model\n",
    "\n",
    "from keras.models import Sequential  ##Sequential represents a linear stack of layers\n",
    "from keras.layers import Dense,Dropout ##Dense is a regular fully connected network layer\n",
    "\n",
    "model=Sequential([\n",
    "Dense(64,activation='relu',input_shape=(784,)),\n",
    "#Dropout(0.5),\n",
    "Dense(64,activation='relu'),\n",
    "#Dropout(0.5),\n",
    "Dense(10,activation='softmax'),\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compiling the Model - Configuring the training process, 3 keys factors: Optimizer, Loss Function, Metrics\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "optimizer='adam',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s - loss: 0.3655 - acc: 0.8905 - val_loss: 0.1911 - val_acc: 0.9429\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s - loss: 0.1813 - acc: 0.9446 - val_loss: 0.1491 - val_acc: 0.9540\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s - loss: 0.1390 - acc: 0.9573 - val_loss: 0.1181 - val_acc: 0.9621\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s - loss: 0.1161 - acc: 0.9646 - val_loss: 0.1320 - val_acc: 0.9590\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s - loss: 0.1016 - acc: 0.9691 - val_loss: 0.0978 - val_acc: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e031242b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Training the model by supplying parameters:-\n",
    "#training data (images and labels), \n",
    "#number of epochs (iterations over the entire dataset)\n",
    "#batch size (number of samples per gradient update)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model.fit(\n",
    "train_images,\n",
    "to_categorical(train_labels),\n",
    "epochs=5,\n",
    "batch_size=32,\n",
    "validation_data=(test_images,to_categorical(test_labels))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9216/10000 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.097803239399567241, 0.96950000000000003]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Testing the model Evaluate function returns a matrix containing test loss and accuracy \n",
    "\n",
    "model.evaluate(\n",
    "test_images,\n",
    "to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "##Use the model to predict\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions. output of our network is 10 probabilities (because of softmax), \n",
    "## so weâ€™ll use np.argmax() to turn those into actual digits.\n",
    "print(np.argmax(predictions,axis=1))\n",
    "\n",
    "#Check the true labels\n",
    "print(test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the model weights\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "##We can now reload the trained model whenever we want by rebuilding it and loading in the saved weights:\n",
    "model.load_weight('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
